{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import gensim\n",
    "import jamo\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from unicode import join_jamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = 'full-nouns-trigram'\n",
    "DATA_DIR = 'lol'\n",
    "\n",
    "DIM = 200\n",
    "\n",
    "if 'nouns' in DATA_TYPE:\n",
    "    MAXLEN_TITLE = 16\n",
    "    MAXLEN_LEDE = 24\n",
    "    MAXLEN_CONTENTS = 128\n",
    "else:\n",
    "    MAXLEN_TITLE = 32\n",
    "    MAXLEN_LEDE = 64\n",
    "    MAXLEN_CONTENTS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINING_DIR = '1-mining'\n",
    "TOKENIZING_DIR = '3-tokenizing'\n",
    "EMBEDDING_DIR = '4-embedding'\n",
    "TRAINING_DATA_DIR = '5-training-data'\n",
    "\n",
    "mining_dir = Path(MINING_DIR) / DATA_DIR\n",
    "tokenizing_dir = Path(TOKENIZING_DIR) / DATA_DIR\n",
    "embedding_dir = Path(EMBEDDING_DIR) / DATA_DIR\n",
    "training_data_dir = Path(TRAINING_DATA_DIR) / DATA_DIR\n",
    "\n",
    "embedding_dir.mkdir(parents=True, exist_ok=True)\n",
    "training_data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_path = embedding_dir / 'news-{}-wv{}.bin'.format(DATA_TYPE, DIM)\n",
    "wv_vector_path = embedding_dir / 'news-{}-wv{}.vec'.format(DATA_TYPE, DIM)\n",
    "\n",
    "ft_model_path = embedding_dir / 'news-{}-ft{}.bin'.format(DATA_TYPE, DIM)\n",
    "ft_vector_path = embedding_dir / 'news-{}-ft{}.vec'.format(DATA_TYPE, DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_input</th>\n",
       "      <th>date_modify</th>\n",
       "      <th>ranking</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>title</th>\n",
       "      <th>lede</th>\n",
       "      <th>office</th>\n",
       "      <th>contents</th>\n",
       "      <th>vod</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51811</th>\n",
       "      <td>20200430</td>\n",
       "      <td>20200430 17:49</td>\n",
       "      <td>20200430 17:56</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>승강_전 다이브 승리 샌드박스 서라벌 세트 선승</td>\n",
       "      <td>일_종각 파크 섬머_스플릿 승강_전 최종_전 세트 샌드박스_게이밍 서라벌_게이밍 승...</td>\n",
       "      <td>인벤</td>\n",
       "      <td>일_종각 파크 섬머_스플릿 승강_전 최종_전 세트 샌드박스_게이밍 서라벌_게이밍 승...</td>\n",
       "      <td>0</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51812</th>\n",
       "      <td>20200430</td>\n",
       "      <td>20200430 16:14</td>\n",
       "      <td>20200430 16:31</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>승강_전 서라벌 샌드박스 베스트_라인업 맞대결</td>\n",
       "      <td>서머 최종_전 대결 서라벌_게이밍 위 샌드박스_게이밍 사진 라이엇_게임즈 제공 마지...</td>\n",
       "      <td>데일리e스포츠</td>\n",
       "      <td>마지막 승강_전 승리 서라벌_게이밍 샌드박스_게이밍 승강_전 기용 베스트_라인업 출...</td>\n",
       "      <td>0</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51813</th>\n",
       "      <td>20200430</td>\n",
       "      <td>20200430 17:50</td>\n",
       "      <td>20200430 17:50</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>일방 전투 승리 샌드박스_게이밍 서라벌_게이밍 상대 세트 승리</td>\n",
       "      <td>일 우리은행 승강_전 최종진_출전 샌드박스_게이밍 서라벌_게이밍 세트 경기 초반 기...</td>\n",
       "      <td>엑스포츠뉴스</td>\n",
       "      <td>일 우리은행 승강_전 최종진_출전 샌드박스_게이밍 서라벌_게이밍 세트 경기 초반 기...</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51814</th>\n",
       "      <td>20200430</td>\n",
       "      <td>20200430 18:05</td>\n",
       "      <td>20200430 18:05</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>승강_전 샌드박스 카운터 기선_제압</td>\n",
       "      <td>용준 기자 최후 승강_전 샌드박스 다이브 공세 흐름 샌드박스 승강_전 최종_전 서전</td>\n",
       "      <td>OSEN</td>\n",
       "      <td>최후 승강_전 샌드박스 다이브 공세 흐름 샌드박스 승강_전 최종_전 서전 승리 장식...</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51815</th>\n",
       "      <td>20200430</td>\n",
       "      <td>20200430 18:51</td>\n",
       "      <td>20200430 18:51</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>승강_전 샌드박스 집중력 혼전 승리 리드</td>\n",
       "      <td>용준 기자 기회 샌드박스 최후 승강_전 생환 승 샌드박스 일_오후_서울</td>\n",
       "      <td>OSEN</td>\n",
       "      <td>기회 샌드박스 최후 승강_전 생환 승 샌드박스 일_오후_서울 종로_롤_파크 아레나 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      date_input     date_modify  ranking thumbnail  \\\n",
       "51811  20200430  20200430 17:49  20200430 17:56       26         1   \n",
       "51812  20200430  20200430 16:14  20200430 16:31       27         1   \n",
       "51813  20200430  20200430 17:50  20200430 17:50       28         1   \n",
       "51814  20200430  20200430 18:05  20200430 18:05       29         1   \n",
       "51815  20200430  20200430 18:51  20200430 18:51       30         1   \n",
       "\n",
       "                                    title  \\\n",
       "51811          승강_전 다이브 승리 샌드박스 서라벌 세트 선승   \n",
       "51812           승강_전 서라벌 샌드박스 베스트_라인업 맞대결   \n",
       "51813  일방 전투 승리 샌드박스_게이밍 서라벌_게이밍 상대 세트 승리   \n",
       "51814                 승강_전 샌드박스 카운터 기선_제압   \n",
       "51815              승강_전 샌드박스 집중력 혼전 승리 리드   \n",
       "\n",
       "                                                    lede   office  \\\n",
       "51811  일_종각 파크 섬머_스플릿 승강_전 최종_전 세트 샌드박스_게이밍 서라벌_게이밍 승...       인벤   \n",
       "51812  서머 최종_전 대결 서라벌_게이밍 위 샌드박스_게이밍 사진 라이엇_게임즈 제공 마지...  데일리e스포츠   \n",
       "51813  일 우리은행 승강_전 최종진_출전 샌드박스_게이밍 서라벌_게이밍 세트 경기 초반 기...   엑스포츠뉴스   \n",
       "51814     용준 기자 최후 승강_전 샌드박스 다이브 공세 흐름 샌드박스 승강_전 최종_전 서전     OSEN   \n",
       "51815            용준 기자 기회 샌드박스 최후 승강_전 생환 승 샌드박스 일_오후_서울     OSEN   \n",
       "\n",
       "                                                contents vod  view  \n",
       "51811  일_종각 파크 섬머_스플릿 승강_전 최종_전 세트 샌드박스_게이밍 서라벌_게이밍 승...   0  1166  \n",
       "51812  마지막 승강_전 승리 서라벌_게이밍 샌드박스_게이밍 승강_전 기용 베스트_라인업 출...   0  1057  \n",
       "51813  일 우리은행 승강_전 최종진_출전 샌드박스_게이밍 서라벌_게이밍 세트 경기 초반 기...   0   835  \n",
       "51814  최후 승강_전 샌드박스 다이브 공세 흐름 샌드박스 승강_전 최종_전 서전 승리 장식...   0   490  \n",
       "51815  기회 샌드박스 최후 승강_전 생환 승 샌드박스 일_오후_서울 종로_롤_파크 아레나 ...   0   460  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(embedding_dir / 'news-{}.csv'.format(DATA_TYPE)).dropna()\n",
    "df.vod = df.vod.astype('int64').astype('category')\n",
    "df.thumbnail = df.thumbnail.astype('int64').astype('category')\n",
    "\n",
    "np.save(training_data_dir / 'news-view.npy', np.asarray(df.view, 'int32'))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec, fasttext embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = df.date.apply(lambda x: 20150000 < x < 20200000)\n",
    "test_range = df.date.apply(lambda x: 20200000 < x < 20210000)\n",
    "\n",
    "def my_train_test_split(data):\n",
    "    return data[train_range], data[test_range]\n",
    "\n",
    "def my_train_val_test_split(data):\n",
    "    train, test = my_train_test_split(data)\n",
    "    train, val = train_test_split(train, test_size=0.1, random_state=119)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.asarray([x.split(' ') + y.split(' ') for x, y in zip(df.title, df.contents)])\n",
    "sentences, _, _ = my_train_val_test_split(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_mod = gensim.models.Word2Vec(sentences, sg=1, size=DIM)\n",
    "wv_mod.save(str(wv_model_path))\n",
    "wv_mod.wv.save_word2vec_format(str(wv_vector_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_mod = gensim.models.FastText(sentences, sg=1, size=DIM)\n",
    "ft_mod.save(str(ft_model_path))\n",
    "ft_mod.wv.save_word2vec_format(str(ft_vector_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da896fd2e2c4601ad12996bf9f97827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51286.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thumbnails = []\n",
    "for row in tqdm(df.itertuples(index=False), total=len(df)):\n",
    "    mining_date_dir = mining_dir / str(row.date)\n",
    "    thumbnail_glob = '{:04d}-*-thumbnail.jpg'.format(row.ranking)\n",
    "    try:\n",
    "        thumbnail_path = next(mining_date_dir.glob(thumbnail_glob))\n",
    "    except StopIteration:\n",
    "        thumbnail = np.asarray(Image.new('RGB', (210, 122), (255, 255, 255)))\n",
    "    else:\n",
    "        thumbnail = np.asarray(Image.open(thumbnail_path).convert('RGB'))\n",
    "    thumbnails.append(thumbnail)\n",
    "\n",
    "thumbnails = np.asarray(thumbnails, 'float32') / 255.0\n",
    "np.save(training_data_dir / 'news-thumbnail.npy', thumbnails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding title & lede & contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "fasttext.util.download_model('ko', if_exists='ignore')\n",
    "\n",
    "ft = fasttext.load_model('cc.ko.300.bin')\n",
    "fasttext.util.reduce_model(ft, 200)\n",
    "\n",
    "EMBED_NAME = 'ft-pre'\n",
    "get_vector = ft.get_word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wv_mod = gensim.models.Word2Vec.load(str(wv_model_path))\n",
    "#EMBED_NAME = 'wv'\n",
    "\n",
    "def get_vector(x):\n",
    "    try:\n",
    "        return wv_mod.wv.get_vector(x)\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_mod = gensim.models.FastText.load(str(ft_model_path))\n",
    "EMBED_NAME = 'ft'\n",
    "get_vector = ft_mod.wv.get_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 1 6.1324727995944315 1.775521857172055\n",
      "25 3 13.04548999727021 2.2777913642670953\n",
      "2245 1 155.44556019186524 123.34196657583232\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "ledes = []\n",
    "contentss = []\n",
    "for title, lede, contents in zip(df.title, df.lede, df.contents):\n",
    "    titles.append(np.asarray([x for x in [get_vector(x) for x in title.split(' ')] if x is not None]))\n",
    "    ledes.append(np.asarray([x for x in [get_vector(x) for x in lede.split(' ')] if x is not None]))\n",
    "    contentss.append(np.asarray([x for x in [get_vector(x) for x in contents.split(' ')] if x is not None]))\n",
    "\n",
    "for x in [[len(x) for x in y] for y in [titles, ledes, contentss]]:\n",
    "    print(max(x), min(x), np.mean(x), np.std(x))\n",
    "\n",
    "titles = tf.keras.preprocessing.sequence.pad_sequences(titles, maxlen=MAXLEN_TITLE, dtype='float32', padding='post', truncating='post')\n",
    "ledes = tf.keras.preprocessing.sequence.pad_sequences(ledes, maxlen=MAXLEN_LEDE, dtype='float32', padding='post', truncating='post')\n",
    "contentss = tf.keras.preprocessing.sequence.pad_sequences(contentss, maxlen=MAXLEN_CONTENTS, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "np.save(training_data_dir / 'news-{}-{}{}-title.npy'.format(DATA_TYPE, EMBED_NAME, DIM), titles)\n",
    "np.save(training_data_dir / 'news-{}-{}{}-lede.npy'.format(DATA_TYPE, EMBED_NAME, DIM), ledes)\n",
    "np.save(training_data_dir / 'news-{}-{}{}-contents.npy'.format(DATA_TYPE, EMBED_NAME, DIM), contentss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

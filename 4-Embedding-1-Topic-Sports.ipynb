{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = 'full-morphs-jamo'\n",
    "DATA_NOSTOPS_TYPE = 'full-nouns-jamo'\n",
    "\n",
    "TOPIC = 40\n",
    "\n",
    "if DATA_TYPE.startswith('outer'):\n",
    "    TEXT_COLUMNS = ['headline', 'lede']\n",
    "elif DATA_TYPE.startswith('inner'):\n",
    "    TEXT_COLUMNS = ['title', 'contents']\n",
    "else:\n",
    "    TEXT_COLUMNS = ['headline', 'lede', 'contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZING_DIR = '3-tokenizing'\n",
    "EMBEDDING_DIR = '4-embedding'\n",
    "DATA_DIR = 'lol'\n",
    "\n",
    "tokenizing_dir = Path(TOKENIZING_DIR) / DATA_DIR\n",
    "embedding_dir = Path(EMBEDDING_DIR) / DATA_DIR\n",
    "embedding_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(df):\n",
    "    data_words = []\n",
    "    for i, *rows in tqdm(df[TEXT_COLUMNS].itertuples(), total=len(df)):\n",
    "        rows = [x for x in rows if isinstance(x, str)]\n",
    "        data_words.append(' '.join(rows).split(' '))\n",
    "    return data_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(tokenizing_dir / 'news-{}.csv'.format(DATA_TYPE)).dropna()\n",
    "contents = [x.split(' ') for x in df.contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(contents)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[contents])\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] if doc is not np.nan else doc for doc in tqdm(texts)]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] if doc is not np.nan else doc for doc in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_mod_path = embedding_dir / 'news-{}-bigram.bin'.format(DATA_TYPE)\n",
    "bigram_mod.save(str(bigram_mod_path))\n",
    "\n",
    "trigram_mod_path = embedding_dir / 'news-{}-trigram.bin'.format(DATA_TYPE)\n",
    "trigram_mod.save(str(trigram_mod_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf41fa863c74445d9436e8470f907080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51816.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526c9c8acbc14e5781716f2ca464e170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51816.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5639530c21cc4da5992a89f854508baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51816.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nostops_df = pd.read_csv(tokenizing_dir / 'news-{}.csv'.format(DATA_NOSTOPS_TYPE))\n",
    "title_nostops = [x.split(' ') if x is not np.nan else x for x in nostops_df.title]\n",
    "lede_nostops = [x.split(' ') if x is not np.nan else x for x in nostops_df.lede]\n",
    "contents_nostops = [x.split(' ') if x is not np.nan else x for x in nostops_df.title]\n",
    "\n",
    "title_bigrams = make_bigrams(title_nostops)\n",
    "lede_bigrams = make_bigrams(lede_nostops)\n",
    "contents_bigrams = make_bigrams(contents_nostops)\n",
    "\n",
    "#data_words_trigrams = make_trigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)]]\n"
     ]
    }
   ],
   "source": [
    "id2word = gensim.corpora.Dictionary(data_words_bigrams)\n",
    "texts = data_words_bigrams\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=TOPIC,\n",
    "    random_state=119,\n",
    "    update_every=1,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,\n",
      "  '0.231*\"원거리_딜러\" + 0.075*\"뱅\" + 0.063*\"배준식\" + 0.058*\"중계\" + 0.042*\"상황\" + '\n",
      "  '0.035*\"오전\" + 0.034*\"일\" + 0.022*\"동시\" + 0.018*\"달\" + 0.017*\"유리\"'),\n",
      " (32,\n",
      "  '0.104*\"말\" + 0.075*\"이후\" + 0.054*\"박종익\" + 0.054*\"투신\" + 0.053*\"프레이\" + '\n",
      "  '0.050*\"선승\" + 0.043*\"김종인\" + 0.029*\"그\" + 0.024*\"시드\" + 0.023*\"오\"'),\n",
      " (27,\n",
      "  '0.073*\"연속\" + 0.040*\"주도\" + 0.036*\"터키\" + 0.034*\"관심\" + 0.033*\"박\" + 0.032*\"출신\" '\n",
      "  '+ 0.031*\"의미\" + 0.030*\"코\" + 0.028*\"흐름\" + 0.026*\"희망\"'),\n",
      " (18,\n",
      "  '0.138*\"서포터\" + 0.096*\"자신\" + 0.089*\"오후_서울\" + 0.053*\"엑_스포츠\" + 0.050*\"션\" + '\n",
      "  '0.049*\"일\" + 0.034*\"차이\" + 0.033*\"강_찬용\" + 0.031*\"소감\" + 0.029*\"마타_조세\"'),\n",
      " (4,\n",
      "  '0.206*\"온라인\" + 0.076*\"압도\" + 0.058*\"스틸\" + 0.055*\"최근\" + 0.052*\"위치\" + '\n",
      "  '0.048*\"맹활약\" + 0.046*\"진행\" + 0.044*\"챔피언십\" + 0.040*\"이유\" + 0.038*\"속\"'),\n",
      " (8,\n",
      "  '0.065*\"후\" + 0.061*\"연승_질주\" + 0.040*\"윤\" + 0.038*\"스피릿\" + 0.038*\"다음\" + '\n",
      "  '0.026*\"영상\" + 0.026*\"날\" + 0.024*\"아쉬움\" + 0.022*\"일\" + 0.021*\"더블_리프트\"'),\n",
      " (0,\n",
      "  '0.160*\"경기력\" + 0.100*\"플리커\" + 0.049*\"오후\" + 0.045*\"실수\" + 0.041*\"시\" + '\n",
      "  '0.041*\"결정\" + 0.040*\"젠\" + 0.038*\"팀\" + 0.028*\"필요\" + 0.025*\"플레이오프\"'),\n",
      " (34,\n",
      "  '0.114*\"미드_라이너\" + 0.065*\"목표\" + 0.063*\"선택\" + 0.060*\"선발_출전\" + 0.048*\"픽\" + '\n",
      "  '0.043*\"데뷔\" + 0.039*\"이야기\" + 0.029*\"경험\" + 0.024*\"올라프\" + 0.021*\"지르\"'),\n",
      " (26,\n",
      "  '0.042*\"등장\" + 0.041*\"년_만\" + 0.031*\"팀\" + 0.030*\"달성\" + 0.029*\"롤\" + 0.028*\"무대\" '\n",
      "  '+ 0.023*\"처음\" + 0.023*\"위_등극\" + 0.023*\"번\" + 0.020*\"년\"'),\n",
      " (23,\n",
      "  '0.069*\"연패_탈출\" + 0.055*\"선발전\" + 0.052*\"한국_대표\" + 0.049*\"복귀\" + 0.036*\"개발\" + '\n",
      "  '0.034*\"일\" + 0.027*\"유통\" + 0.025*\"라이엇_게임즈\" + 0.025*\"레전드\" + 0.024*\"연기\"'),\n",
      " (30,\n",
      "  '0.095*\"정글\" + 0.051*\"세트\" + 0.041*\"탑\" + 0.038*\"초반\" + 0.032*\"승리\" + 0.025*\"챔피언\" '\n",
      "  '+ 0.023*\"중요\" + 0.023*\"활약\" + 0.023*\"피넛\" + 0.022*\"공격\"'),\n",
      " (24,\n",
      "  '0.227*\"진에어\" + 0.098*\"챌린저\" + 0.097*\"윙스\" + 0.057*\"코리아\" + 0.047*\"스프링\" + '\n",
      "  '0.029*\"일\" + 0.027*\"이성진\" + 0.025*\"챌린저_스\" + 0.025*\"강동훈_감독\" + 0.023*\"하위\"'),\n",
      " (37,\n",
      "  '0.364*\"스포츠\" + 0.050*\"일\" + 0.043*\"북미\" + 0.042*\"유럽\" + 0.038*\"대표\" + 0.027*\"팀\" '\n",
      "  '+ 0.023*\"중국\" + 0.013*\"리그\" + 0.013*\"게임\" + 0.012*\"클라우드_나인\"'),\n",
      " (9,\n",
      "  '0.130*\"세트\" + 0.121*\"승\" + 0.098*\"대\" + 0.083*\"주\" + 0.070*\"리그_오브\" + 0.061*\"환사\" '\n",
      "  '+ 0.056*\"협곡\" + 0.055*\"언스_코리아\" + 0.055*\"레전드_챔피\" + 0.036*\"스프링\"'),\n",
      " (5,\n",
      "  '0.236*\"드_컵\" + 0.172*\"롤\" + 0.060*\"월드_챔피언십\" + 0.045*\"일\" + 0.042*\"레전드\" + '\n",
      "  '0.038*\"이하\" + 0.038*\"리그_오브\" + 0.027*\"강\" + 0.021*\"스코어\" + 0.020*\"팀\"'),\n",
      " (29,\n",
      "  '0.158*\"위\" + 0.147*\"드래곤\" + 0.087*\"일\" + 0.083*\"승\" + 0.068*\"월\" + 0.066*\"패\" + '\n",
      "  '0.056*\"순위\" + 0.051*\"기준\" + 0.035*\"팀\" + 0.022*\"리그_오브\"'),\n",
      " (6,\n",
      "  '0.174*\"세트\" + 0.150*\"승리\" + 0.044*\"상대\" + 0.024*\"일\" + 0.020*\"경기\" + 0.019*\"킬\" + '\n",
      "  '0.019*\"아이_뉴스\" + 0.018*\"이\" + 0.018*\"초반\" + 0.017*\"대\"'),\n",
      " (10,\n",
      "  '0.157*\"일\" + 0.097*\"코리아\" + 0.088*\"챔피_언스\" + 0.082*\"롤스터\" + 0.080*\"경기\" + '\n",
      "  '0.061*\"차\" + 0.038*\"섬머\" + 0.035*\"이하\" + 0.032*\"서울\" + 0.030*\"전\"'),\n",
      " (21,\n",
      "  '0.149*\"스프링\" + 0.122*\"일\" + 0.097*\"레전드_챔피\" + 0.096*\"리그_오브\" + 0.086*\"언스_코리아\" + '\n",
      "  '0.063*\"라운드\" + 0.054*\"이하\" + 0.054*\"경기\" + 0.031*\"차\" + 0.030*\"주\"'),\n",
      " (35,\n",
      "  '0.144*\"라이엇_게임즈\" + 0.072*\"레전드\" + 0.070*\"리그_오브\" + 0.058*\"제공\" + 0.052*\"일\" + '\n",
      "  '0.037*\"한국\" + 0.036*\"팀\" + 0.033*\"사진\" + 0.033*\"선수\" + 0.030*\"스포츠\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -15.71150994487184\n",
      "Coherence Score:  0.3558041773977927\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', lda_model.log_perplexity(corpus)) # a measure of how good the model is. lower the better.\n",
    "\n",
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_path = embedding_dir / 'news-{}-{}-lda-topic{}-visualization.html'.format(DATA_NOSTOPS_TYPE, '-'.join(TEXT_COLUMNS), TOPIC)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.save_html(vis, open(vis_path, 'w'))\n",
    "#vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_path = embedding_dir / 'news-{}-{}-lda-topic{}.bin'.format(DATA_NOSTOPS_TYPE, '-'.join(TEXT_COLUMNS), TOPIC)\n",
    "lda_model.save(str(lda_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
